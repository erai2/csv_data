# universal_parser.py
# parser.py
import os
import json
import re

def split_paragraphs(text):
    """
    ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (ë¹ˆ ì¤„ ê¸°ì¤€)
    """
    return [p.strip() for p in text.split("\n\n") if p.strip()]

def classify_paragraph(para):
    """
    ë¬¸ë‹¨ì„ rule / case / concept ìœ¼ë¡œ ë¶„ë¥˜
    - ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ (ì¶”í›„ AI ëª¨ë¸ ì—°ë™ ê°€ëŠ¥)
    """
    # ê·œì¹™ (rules)
    if any(kw in para for kw in ["åˆ", "æ²–", "åˆ‘", "ç ´", "ç©¿", "ë¬˜ê³ ", "í—ˆì‹¤", "å¸¶è±¡", "ì‘ê¸°", "ì¡°ê±´"]):
        return "rule"

    # ì‚¬ë¡€ (cases)
    if any(kw in para for kw in ["ì‚¬ë¡€", "ì˜ˆì‹œ", "ì‚¬ì£¼", "ë‚¨ëª…", "ì—¬ëª…", "ì¼ì£¼", "ëŒ€ìš´", "ì„¸ìš´"]):
        return "case"

    # ê°œë… (concepts)
    if any(kw in para for kw in ["ì˜ë¯¸", "ì •ì˜", "ì„¤ëª…", "ìƒ", "ë²•", "ì›ë¦¬", "ê¶ìœ„", "ì‹­ì‹ ", "ì˜¤í–‰"]):
        return "concept"

    return "unknown"

def parse_document(content):
    """
    ë¬¸ì„œ â†’ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ì¶”ì¶œ + ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    """
    result = {"paragraphs": []}
    for i, para in enumerate(split_paragraphs(content), 1):
        result["paragraphs"].append({
            "id": i,
            "category": classify_paragraph(para),
            "content": para
        })
    return result

def parse_documents(folder="docs"):
    """
    docs í´ë”ì˜ ëª¨ë“  .txt/.md ë¬¸ì„œë¥¼ JSONìœ¼ë¡œ ë³€í™˜
    """
    parsed = {}
    for fname in os.listdir(folder):
        if not fname.endswith((".txt", ".md")):
            continue
        with open(os.path.join(folder, fname), encoding="utf-8") as f:
            content = f.read()
        parsed[fname] = parse_document(content)

    with open("parsed_all.json", "w", encoding="utf-8") as f:
        json.dump(parsed, f, ensure_ascii=False, indent=2)

    return parsed

if __name__ == "__main__":
    os.makedirs("docs", exist_ok=True)
    result = parse_documents("docs")
    print("âœ… ë¬¸ë‹¨ + ì¹´í…Œê³ ë¦¬ íŒŒì‹± ì™„ë£Œ â†’ parsed_all.json")
    print("ğŸ“‚ ì²˜ë¦¬ëœ íŒŒì¼:", list(result.keys()))
