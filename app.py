"""Streamlit entry point for the explainable fortune inference system."""

from __future__ import annotations

import json
from pathlib import Path
from typing import Dict, Iterable, List, Sequence, Tuple

import streamlit as st
import pandas as pd

from utils import extractor_v4
from utils.db_manager import (
    init_db,
    list_cases,
    list_concepts,
    list_principles,
    list_relations,
    list_rules,
    record_cases,
    record_concepts,
    record_principles,
    record_relations,
    record_rules,
    search_cases,
    search_concepts,
    search_relations,
    search_rules,
)
from utils.logic_infer_explainable import infer_logic_explainable
from utils.profile_manager import delete_profile, list_profiles, load_profile, save_profile
from utils.saju_core_v2 import EARTHLY_BRANCHES, HEAVENLY_STEMS, analyze_saju
from utils.visualize_v3 import draw_relation_network


st.set_page_config(page_title="AI ëª…ë¦¬ í•´ì„ ì‹œìŠ¤í…œ v13.2", layout="wide")
st.title("ğŸª¶ AI ëª…ë¦¬ í•´ì„ ì‹œìŠ¤í…œ (Explainable Ver.)")


# ---------------------------------------------------------------------------
# Initial session state
# ---------------------------------------------------------------------------
DEFAULT_GAN = ["ä¸", "æˆŠ", "è¾›", "è¾›"]
DEFAULT_ZHI = ["åˆ", "å¯", "äº¥", "å­"]

GAN_KEYS = ["gan_si", "gan_il", "gan_wol", "gan_nyeon"]
ZHI_KEYS = ["zhi_si", "zhi_il", "zhi_wol", "zhi_nyeon"]


def _ensure_session_defaults() -> None:
    for key, value in zip(GAN_KEYS, DEFAULT_GAN):
        st.session_state.setdefault(key, value)
    for key, value in zip(ZHI_KEYS, DEFAULT_ZHI):
        st.session_state.setdefault(key, value)
    st.session_state.setdefault("gan_input", " ".join(DEFAULT_GAN))
    st.session_state.setdefault("zhi_input", " ".join(DEFAULT_ZHI))
    st.session_state.setdefault("daewoon", "ç”²åˆ")
    st.session_state.setdefault("sewoon", "ä¹™äº¥")
    st.session_state.setdefault("profile_to_load", "ìƒˆ í”„ë¡œí•„")
    st.session_state.setdefault("latest_structure", None)
    st.session_state.setdefault("latest_results", None)
    st.session_state.setdefault("latest_profile_name", "analysis")


def _sync_gan_from_selects() -> None:
    st.session_state["gan_input"] = " ".join(st.session_state[key] for key in GAN_KEYS)


def _sync_zhi_from_selects() -> None:
    st.session_state["zhi_input"] = " ".join(st.session_state[key] for key in ZHI_KEYS)


def _sync_selects_from_gan() -> None:
    parts = st.session_state.get("gan_input", "").split()
    for idx, key in enumerate(GAN_KEYS):
        if idx < len(parts) and parts[idx] in HEAVENLY_STEMS:
            st.session_state[key] = parts[idx]


def _sync_selects_from_zhi() -> None:
    parts = st.session_state.get("zhi_input", "").split()
    for idx, key in enumerate(ZHI_KEYS):
        if idx < len(parts) and parts[idx] in EARTHLY_BRANCHES:
            st.session_state[key] = parts[idx]


_ensure_session_defaults()


# ---------------------------------------------------------------------------
# Database bootstrapping
# ---------------------------------------------------------------------------
init_db()


# ---------------------------------------------------------------------------
# Helper utilities
# ---------------------------------------------------------------------------
def _save_uploaded_file(uploaded_file) -> Tuple[Path, bool]:
    """Persist an uploaded file, routing sensitive names to a secure folder."""

    uploads_dir = Path("data/uploads")
    secure_dir = Path("data/protected")

    sensitive_names = {".env", "env", "secrets.env", ".gitignore"}
    sensitive_suffixes = (".env", ".gitignore", ".streamlit", ".secrets")

    file_name = uploaded_file.name
    file_lower = file_name.lower()
    is_sensitive = file_lower in sensitive_names or any(file_lower.endswith(suffix) for suffix in sensitive_suffixes)

    target_dir = secure_dir if is_sensitive else uploads_dir
    target_dir.mkdir(parents=True, exist_ok=True)

    file_path = target_dir / file_name
    with open(file_path, "wb") as buffer:
        buffer.write(uploaded_file.read())

    return file_path, is_sensitive


def _convert_terms_to_principles(terms: Iterable[Dict[str, str]]) -> List[Dict[str, str]]:
    return [
        {"title": term.get("term", ""), "definition": term.get("definition", ""), "category": term.get("category", "ìš©ì–´")}
        for term in terms
    ]


def _cases_to_relations(cases: Iterable[Dict[str, str]]) -> List[Dict[str, str]]:
    payload: List[Dict[str, str]] = []
    for case in cases:
        raw_tags = case.get("tags", [])
        if isinstance(raw_tags, str):
            tags = [tag.strip() for tag in raw_tags.split(",") if tag.strip()]
        else:
            tags = [str(tag).strip() for tag in raw_tags if str(tag).strip()]
        for tag in tags or ["ê¸°íƒ€"]:
            payload.append(
                {
                    "relation_type": tag,
                    "description": case.get("summary", ""),
                    "source": case.get("title", "case"),
                }
            )
    return payload


def _structure_relations_to_edges(relations: Sequence[str]) -> List[Tuple[str, str, str]]:
    edges: List[Tuple[str, str, str]] = []
    for relation in relations:
        if len(relation) >= 3:
            source, target, rel_type = relation[0], relation[1], relation[2:]
            if source in EARTHLY_BRANCHES and target in EARTHLY_BRANCHES:
                edges.append((source, target, rel_type))
    return edges


# ---------------------------------------------------------------------------
# Layout
# ---------------------------------------------------------------------------
tabs = st.tabs(
    [
        "ğŸ“„ ë¬¸ì„œ ì •ë¦¬/ì‹œê°í™”",
        "ğŸª¶ ì‚¬ì£¼ ëª…ì¡° ë° ìš´ì„¸ í•´ì„",
        "ğŸ‘¤ í”„ë¡œí•„ ê´€ë¦¬",
        "ğŸŒ ì‹œê°í™”",
        "ğŸ“˜ ë¦¬í¬íŠ¸",
    ]
)


# ---------------------------------------------------------------------------
# Tab 1: ë¬¸ì„œ ì •ë¦¬/ì‹œê°í™”
# ---------------------------------------------------------------------------
with tabs[0]:
    st.header("ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ ë° ì§€ì‹ ì •ë¦¬")
    uploaded = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["txt", "docx", "pdf", "zip"])

    if uploaded is not None:
        saved_path, is_sensitive = _save_uploaded_file(uploaded)
        if is_sensitive:
            st.warning(f"ğŸ” ë³´ì•ˆ íŒŒì¼ë¡œ ë¶„ë¥˜ë˜ì–´ ë³„ë„ ì˜ì—­ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {saved_path}")
        else:
            extracted = extractor_v4.extract_rules_terms_cases(str(saved_path))
            st.session_state["doc_source"] = saved_path.name
            st.session_state["doc_source_path"] = str(saved_path)
            st.session_state["doc_concepts"] = [
                {
                    "title": concept.get("title", ""),
                    "content": concept.get("content", ""),
                    "category": concept.get("category", "") or "ê°œë…",
                }
                for concept in extracted.get("concepts", [])
            ]
            st.session_state["doc_cases"] = [
                {
                    "title": case.get("title", ""),
                    "chart": case.get("chart", ""),
                    "summary": case.get("summary", ""),
                    "content": case.get("content", ""),
                    "tags": ", ".join(case.get("tags", [])),
                }
                for case in extracted.get("cases", [])
            ]
            st.session_state["doc_rules"] = extracted.get("rules", [])
            st.session_state["doc_terms"] = extracted.get("terms", [])
            st.success(
                "ğŸ“¥ ì¶”ì¶œ ì™„ë£Œ â€” ê°œë… {concepts}ê±´, ì‚¬ë¡€ {cases}ê±´. ì €ì¥ ì „ì— ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.".format(
                    concepts=len(st.session_state["doc_concepts"]),
                    cases=len(st.session_state["doc_cases"]),
                )
            )

    concepts_state = st.session_state.get("doc_concepts", [])
    cases_state = st.session_state.get("doc_cases", [])
    rules_state = st.session_state.get("doc_rules", [])
    terms_state = st.session_state.get("doc_terms", [])
    source_name = st.session_state.get("doc_source")

    if concepts_state or cases_state:
        st.info(
            "ğŸ“„ `{}` ì¶”ì¶œ ê²°ê³¼ë¥¼ ê²€í†  í›„ í•„ìš” ì‹œ ìˆ˜ì •í•˜ê³  ì €ì¥í•˜ì„¸ìš”.".format(source_name)
            if source_name
            else "ğŸ“„ ì¶”ì¶œ ê²°ê³¼ë¥¼ ê²€í†  í›„ í•„ìš” ì‹œ ìˆ˜ì •í•˜ê³  ì €ì¥í•˜ì„¸ìš”."
        )

        concept_df = pd.DataFrame(concepts_state)
        if concept_df.empty:
            concept_df = pd.DataFrame(columns=["title", "content", "category"])
        edited_concepts = st.data_editor(
            concept_df,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                "title": st.column_config.TextColumn("ì œëª©", width="medium"),
                "content": st.column_config.TextColumn("ë‚´ìš©", width="large"),
                "category": st.column_config.TextColumn("ë¶„ë¥˜", width="small"),
            },
            key="concept_editor",
        )
        st.session_state["doc_concepts"] = (
            edited_concepts.fillna("").to_dict("records") if not edited_concepts.empty else []
        )

        st.markdown("### ì‚¬ë¡€ (ë³¸ë¬¸ í¬í•¨)")
        cases_df = pd.DataFrame(cases_state)
        if cases_df.empty:
            cases_df = pd.DataFrame(columns=["title", "chart", "summary", "content", "tags"])
        edited_cases = st.data_editor(
            cases_df,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                "title": st.column_config.TextColumn("ì œëª©", width="medium"),
                "chart": st.column_config.TextColumn("ëª…ì¡°", width="small"),
                "summary": st.column_config.TextColumn("ìš”ì•½", width="medium"),
                "content": st.column_config.TextColumn("ë³¸ë¬¸", width="large"),
                "tags": st.column_config.TextColumn("íƒœê·¸ (ì‰¼í‘œ êµ¬ë¶„)", width="medium"),
            },
            key="case_editor",
        )
        st.session_state["doc_cases"] = (
            edited_cases.fillna("").to_dict("records") if not edited_cases.empty else []
        )

        with st.expander("ğŸ§¾ ê·œì¹™Â·ìš©ì–´ (ì°¸ê³ )", expanded=False):
            st.markdown("**ê·œì¹™**")
            st.dataframe(pd.DataFrame(rules_state) if rules_state else pd.DataFrame(columns=["condition", "result"]))
            st.markdown("**ìš©ì–´**")
            st.dataframe(pd.DataFrame(terms_state) if terms_state else pd.DataFrame(columns=["term", "definition"]))

        if st.button("ğŸ’¾ ìˆ˜ì • ë‚´ìš© DB ì €ì¥", type="primary"):
            source_label = st.session_state.get("doc_source", "")
            concept_payload = [
                {
                    "title": item.get("title", "").strip(),
                    "content": item.get("content", "").strip(),
                    "category": item.get("category", "") or "ê°œë…",
                    "source": source_label,
                }
                for item in st.session_state.get("doc_concepts", [])
                if item.get("title") or item.get("content")
            ]

            case_payload = []
            for item in st.session_state.get("doc_cases", []):
                tags_field = item.get("tags", "")
                if isinstance(tags_field, str):
                    tags_list = [tag.strip() for tag in tags_field.split(",") if tag.strip()]
                else:
                    tags_list = [str(tag).strip() for tag in tags_field if str(tag).strip()]
                payload_item = {
                    "title": item.get("title", "").strip(),
                    "chart": item.get("chart", "").strip(),
                    "summary": item.get("summary", "").strip(),
                    "content": item.get("content", ""),
                    "tags": tags_list,
                    "source": source_label,
                }
                if payload_item["title"] or payload_item["content"]:
                    case_payload.append(payload_item)

            record_concepts(concept_payload, source=source_label)
            record_cases(case_payload, source=source_label)
            record_rules(st.session_state.get("doc_rules", []))
            record_principles(_convert_terms_to_principles(st.session_state.get("doc_terms", [])))
            record_relations(_cases_to_relations(case_payload))

            st.success(
                "âœ… DB ì €ì¥ ì™„ë£Œ â€” ê°œë… {concepts}ê±´, ì‚¬ë¡€ {cases}ê±´".format(
                    concepts=len(concept_payload),
                    cases=len(case_payload),
                )
            )

            for key in ["doc_concepts", "doc_cases", "doc_rules", "doc_terms", "doc_source", "doc_source_path"]:
                st.session_state.pop(key, None)

    st.markdown("---")
    st.subheader("ğŸ” ì €ì¥ ë°ì´í„° ê²€ìƒ‰")
    col_concept_search, col_case_search = st.columns(2)
    with col_concept_search:
        concept_keyword = st.text_input("ê°œë… ê²€ìƒ‰ì–´", "", key="concept_search")
        if concept_keyword:
            st.dataframe(search_concepts(concept_keyword, limit=50))
        else:
            st.dataframe(list_concepts(limit=20))
    with col_case_search:
        case_keyword = st.text_input("ì‚¬ë¡€ ê²€ìƒ‰ì–´", "", key="case_search")
        if case_keyword:
            st.dataframe(search_cases(case_keyword, limit=50))
        else:
            st.dataframe(list_cases(limit=20))

    st.subheader("ğŸ” ê·œì¹™ / ê´€ê³„ ê²€ìƒ‰")
    col_search_rule, col_search_relation = st.columns(2)
    with col_search_rule:
        keyword = st.text_input("ê·œì¹™ ê²€ìƒ‰ì–´", "", key="rule_search")
        if keyword:
            st.dataframe(search_rules(keyword))
        else:
            st.dataframe(list_rules(limit=20))
    with col_search_relation:
        relation_keyword = st.text_input("ê´€ê³„ ê²€ìƒ‰ì–´", "", key="relation_search")
        if relation_keyword:
            st.dataframe(search_relations(relation_keyword))
        else:
            st.dataframe(list_relations(limit=20))


# ---------------------------------------------------------------------------
# Tab 2: ì‚¬ì£¼ ëª…ì¡° ë° ìš´ì„¸ í•´ì„
# ---------------------------------------------------------------------------
with tabs[1]:
    st.header("ğŸª¶ ì‚¬ì£¼ ëª…ì¡° ë° ìš´ì„¸ í•´ì„")

    profiles = list_profiles()
    options = {"ìƒˆ í”„ë¡œí•„": None}
    options.update({f"{p['name']} (#{p['id']})": p["id"] for p in profiles})
    selected_option = st.selectbox("ì €ì¥ëœ í”„ë¡œí•„ ë¶ˆëŸ¬ì˜¤ê¸°", list(options.keys()), key="profile_to_load")

    if selected_option != "ìƒˆ í”„ë¡œí•„":
        selected_profile = load_profile(options[selected_option])
    else:
        selected_profile = None

    if selected_profile is not None and st.button("í”„ë¡œí•„ ê°’ ë¶ˆëŸ¬ì˜¤ê¸°"):
        gan_values = selected_profile["gan"].split()
        zhi_values = selected_profile["zhi"].split()
        for idx, key in enumerate(GAN_KEYS):
            if idx < len(gan_values) and gan_values[idx] in HEAVENLY_STEMS:
                st.session_state[key] = gan_values[idx]
        for idx, key in enumerate(ZHI_KEYS):
            if idx < len(zhi_values) and zhi_values[idx] in EARTHLY_BRANCHES:
                st.session_state[key] = zhi_values[idx]
        st.session_state["gan_input"] = selected_profile["gan"]
        st.session_state["zhi_input"] = selected_profile["zhi"]
        st.session_state["daewoon"] = selected_profile["daewoon"]
        st.session_state["sewoon"] = selected_profile["sewoon"]
        st.session_state["latest_structure"] = selected_profile["structure"]
        st.session_state["latest_results"] = selected_profile["results"]
        st.session_state["latest_profile_name"] = selected_profile["name"]
        st.experimental_rerun()

    col1, col2, col3 = st.columns(3)
    with col1:
        name = st.text_input("ì´ë¦„", value=selected_profile["name"] if selected_profile else "")
        gender = st.selectbox("ì„±ë³„", ["å¤(ì—¬)", "ä¹¾(ë‚¨)"], index=0 if not selected_profile or selected_profile["gender"] == "å¤(ì—¬)" else 1)
    with col2:
        st.markdown("**ì²œê°„ ì„ íƒ (ì‹œÂ·ì¼Â·ì›”Â·ë…„)**")
        st.selectbox("ì‹œì£¼ ì²œê°„", HEAVENLY_STEMS, key="gan_si", on_change=_sync_gan_from_selects)
        st.selectbox("ì¼ì£¼ ì²œê°„", HEAVENLY_STEMS, key="gan_il", on_change=_sync_gan_from_selects)
        st.selectbox("ì›”ì£¼ ì²œê°„", HEAVENLY_STEMS, key="gan_wol", on_change=_sync_gan_from_selects)
        st.selectbox("ë…„ì£¼ ì²œê°„", HEAVENLY_STEMS, key="gan_nyeon", on_change=_sync_gan_from_selects)
    with col3:
        st.markdown("**ì§€ì§€ ì„ íƒ (ì‹œÂ·ì¼Â·ì›”Â·ë…„)**")
        st.selectbox("ì‹œì£¼ ì§€ì§€", EARTHLY_BRANCHES, key="zhi_si", on_change=_sync_zhi_from_selects)
        st.selectbox("ì¼ì£¼ ì§€ì§€", EARTHLY_BRANCHES, key="zhi_il", on_change=_sync_zhi_from_selects)
        st.selectbox("ì›”ì£¼ ì§€ì§€", EARTHLY_BRANCHES, key="zhi_wol", on_change=_sync_zhi_from_selects)
        st.selectbox("ë…„ì£¼ ì§€ì§€", EARTHLY_BRANCHES, key="zhi_nyeon", on_change=_sync_zhi_from_selects)

    st.markdown("---")
    st.markdown("### âœï¸ ì§ì ‘ ì…ë ¥ (ì›í•˜ë©´ ìˆ˜ì • ê°€ëŠ¥)")
    st.text_input("ì²œê°„ ì…ë ¥ (ì‹œ ì¼ ì›” ë…„ ìˆœ)", key="gan_input", on_change=_sync_selects_from_gan)
    st.text_input("ì§€ì§€ ì…ë ¥ (ì‹œ ì¼ ì›” ë…„ ìˆœ)", key="zhi_input", on_change=_sync_selects_from_zhi)

    col_daewoon, col_sewoon = st.columns(2)
    with col_daewoon:
        st.text_input("ëŒ€ìš´", key="daewoon")
    with col_sewoon:
        st.text_input("ì„¸ìš´", key="sewoon")

    if st.button("ğŸ” í•´ì„ ì‹¤í–‰"):
        gan_values = st.session_state["gan_input"].split()
        zhi_values = st.session_state["zhi_input"].split()
        structure = analyze_saju(gan_values, zhi_values, gender)
        results = infer_logic_explainable(structure, st.session_state["daewoon"], st.session_state["sewoon"])

        st.session_state["latest_structure"] = structure
        st.session_state["latest_results"] = results
        st.session_state["latest_profile_name"] = name or "analysis"

        st.subheader("ğŸŒ¿ ì›êµ­ êµ¬ì¡°")
        st.json(structure)

        st.subheader("ğŸ§  í•´ì„ ê²°ê³¼ (ì›ë¦¬ í¬í•¨)")
        for result in results:
            with st.expander(f"ğŸ“‚ {result['ë¶„ì•¼']} â€” {result['ê²°ê³¼']}"):
                st.markdown(f"**ê·¼ê±°:** {result['ê·¼ê±°']}")
                st.markdown(f"**í•´ì„ ì›ë¦¬:** {result['ì›ë¦¬']}")

        save_profile(
            name or "ë¬´ëª…",
            gender,
            st.session_state["gan_input"],
            st.session_state["zhi_input"],
            st.session_state["daewoon"],
            st.session_state["sewoon"],
            structure,
            results,
        )
        st.success(f"âœ… í”„ë¡œí•„ [{name or 'ë¬´ëª…'}] ì €ì¥ ì™„ë£Œ")


# ---------------------------------------------------------------------------
# Tab 3: í”„ë¡œí•„ ê´€ë¦¬
# ---------------------------------------------------------------------------
with tabs[2]:
    st.header("ğŸ‘¤ í”„ë¡œí•„ ê´€ë¦¬")
    profiles = list_profiles()

    if not profiles:
        st.info("ì €ì¥ëœ í”„ë¡œí•„ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for profile in profiles:
            with st.expander(f"ğŸª¶ {profile['name']} ({profile['gender']})"):
                st.markdown(f"**ëŒ€ìš´:** {profile['daewoon']} / **ì„¸ìš´:** {profile['sewoon']}")
                st.markdown(f"**ëª…ì¡°:** {profile['gan']} | {profile['zhi']}")
                structure = json.loads(profile["structure_json"])
                results = json.loads(profile["result_json"])
                st.json(structure)
                for result in results:
                    st.markdown(f"- {result['ë¶„ì•¼']}: {result['ê²°ê³¼']}")
                if st.button(f"ì‚­ì œ_{profile['id']}", key=f"delete_profile_{profile['id']}"):
                    delete_profile(profile["id"])
                    st.warning(f"{profile['name']} í”„ë¡œí•„ ì‚­ì œë¨")
                    st.experimental_rerun()


# ---------------------------------------------------------------------------
# Tab 4: ì‹œê°í™”
# ---------------------------------------------------------------------------
with tabs[3]:
    st.header("ğŸŒ ëª…ì¡° êµ¬ì¡° ì‹œê°í™”")
    latest_structure = st.session_state.get("latest_structure")

    if latest_structure:
        st.markdown("#### ìµœì‹  í•´ì„ ê¸°ë°˜ ê´€ê³„ë§")
        edges = _structure_relations_to_edges(latest_structure.get("ê´€ê³„", []))
        if edges:
            html_path = draw_relation_network(st.session_state.get("latest_profile_name", "analysis"), edges)
            with open(html_path, "r", encoding="utf-8") as html_file:
                st.components.v1.html(html_file.read(), height=620, scrolling=True)
        else:
            st.info("í‘œì‹œí•  ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ë¨¼ì € í•´ì„ì„ ì‹¤í–‰í•˜ë©´ ê´€ê³„ë§ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("ğŸ›  ìˆ˜ë™ ê´€ê³„ ì…ë ¥")
    st.caption("í•œ ì¤„ì— `ì§€ì§€1 ì§€ì§€2 ê´€ê³„ìœ í˜•` í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ) `åˆ å¯ ç ´`")
    manual_relations = st.text_area("ê´€ê³„ ëª©ë¡", "")
    if st.button("ìˆ˜ë™ ì‹œê°í™” ì‹¤í–‰"):
        edges: List[Tuple[str, str, str]] = []
        for line in manual_relations.splitlines():
            parts = line.strip().split()
            if len(parts) >= 3:
                edges.append((parts[0], parts[1], " ".join(parts[2:])))
        if edges:
            html_path = draw_relation_network("manual", edges)
            with open(html_path, "r", encoding="utf-8") as html_file:
                st.components.v1.html(html_file.read(), height=620, scrolling=True)
        else:
            st.warning("ìœ íš¨í•œ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")


# ---------------------------------------------------------------------------
# Tab 5: ë¦¬í¬íŠ¸
# ---------------------------------------------------------------------------
with tabs[4]:
    st.header("ğŸ“˜ ë¦¬í¬íŠ¸")
    st.subheader("ğŸ“š ì €ì¥ëœ ì§€ì‹ ìš”ì•½")
    principles = list_principles(limit=200)
    rules = list_rules(limit=200)
    concepts = list_concepts(limit=200)
    cases = list_cases(limit=200)
    st.markdown(f"- ì›ë¦¬ ì •ì˜: {len(principles)}ê±´")
    st.markdown(f"- ê·œì¹™: {len(rules)}ê±´")
    st.markdown(f"- ê°œë… ë¬¸ë‹¨: {len(concepts)}ê±´")
    st.markdown(f"- ì‚¬ë¡€: {len(cases)}ê±´")

    col_principles, col_rules = st.columns(2)
    with col_principles:
        st.dataframe(principles)
    with col_rules:
        st.dataframe(rules)

    col_concepts, col_cases = st.columns(2)
    with col_concepts:
        st.dataframe(concepts)
    with col_cases:
        st.dataframe(cases)

    st.markdown("---")
    st.subheader("ğŸ—‚ í”„ë¡œí•„ ë¦¬í¬íŠ¸")
    profiles = list_profiles()
    if not profiles:
        st.info("ë‹¤ìš´ë¡œë“œí•  í”„ë¡œí•„ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        profile_options = {f"{p['name']} (#{p['id']})": p for p in profiles}
        selected = st.selectbox("ë¦¬í¬íŠ¸ë¡œ í™•ì¸í•  í”„ë¡œí•„", list(profile_options.keys()))
        profile_payload = profile_options[selected]
        payload = {
            "name": profile_payload["name"],
            "gender": profile_payload["gender"],
            "gan": profile_payload["gan"],
            "zhi": profile_payload["zhi"],
            "daewoon": profile_payload["daewoon"],
            "sewoon": profile_payload["sewoon"],
            "structure": json.loads(profile_payload["structure_json"]),
            "results": json.loads(profile_payload["result_json"]),
        }
        st.json(payload)
        st.download_button(
            label="JSON ë‹¤ìš´ë¡œë“œ",
            data=json.dumps(payload, ensure_ascii=False, indent=2),
            file_name=f"profile_{profile_payload['id']}.json",
            mime="application/json",
        )

